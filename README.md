# VisionAI App - AI-Powered Image Recognition

## ğŸ“Œ Overview
The **VisionAI App Backend** is a machine learning-powered image recognition system that uses **TensorFlow.js** for feature extraction and **Pinecone** as a vector database for similarity search. The application allows users to train the model with new images and later detect objects by querying against the trained dataset.

### ğŸš€ Features
- **Train Mode**: Capture an image, extract features, and store embeddings in Pinecone.
- **Detect Mode**: Capture an image, extract features, and search Pinecone for the most similar object.
- **MobileNet Model**: Uses either:
   - âœ… A pre-trained **MobileNet v2** model loaded dynamically from TensorFlow.js.
   - âœ… A **custom-trained MobileNet v2 model** stored locally.
- **Pinecone Integration**: Stores and retrieves high-dimensional embeddings for efficient similarity search.
- **Node.js & TensorFlow.js**: Eliminates the need for Python dependencies by using TensorFlow.js in a Node.js environment.

---

## ğŸ“‚ Project Structure

```
vision-app/
â”œâ”€â”€ server/                         # Backend (Node.js, TensorFlow.js, Pinecone)
â”‚   â”œâ”€â”€ services/                   # Core backend services
â”‚   â”‚   â”œâ”€â”€ logger/                 # Logging service
â”‚   â”‚   â”‚   â”œâ”€â”€ LoggerService.ts    # Main logging utility
â”‚   â”‚   â”‚   â”œâ”€â”€ types/              # Logger type definitions
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ DebugLevel.ts   # Debugging levels
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ILog.ts         # Logging interface
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts        # Type exports
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ITrackable.ts   # Trackable entity interface
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ log.ts          # Log structure definition
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ LogType.ts      # Enum for log types
â”‚   â”œâ”€â”€ src/                        # Main backend logic
â”‚   â”‚   â”œâ”€â”€ embeddings.ts           # Embedding management
â”‚   â”‚   â”œâ”€â”€ handlers.ts             # Request handlers
â”‚   â”‚   â”œâ”€â”€ index.mts               # Main entry point (ES module)
â”‚   â”‚   â”œâ”€â”€ pinecone.ts             # Pinecone database interactions
â”‚   â”‚   â”œâ”€â”€ routes.ts               # API routes
â”‚   â”‚   â”œâ”€â”€ utils.ts                # Helper functions
â”‚   â”œâ”€â”€ .env                        # Environment variables
â”‚   â”œâ”€â”€ .env.example                # Environment variables
â”‚   â”œâ”€â”€ README.md                   # Backend documentation
â”‚   â”œâ”€â”€ dist                        # Dependencies & scripts
â”‚   â”œâ”€â”€ package.json                # Dependencies & scripts
â”‚   â”œâ”€â”€ pnpm-lock.json              # Dependencies & scripts
â”‚   â”œâ”€â”€ requirements.txt            # Dependencies & scripts
â”‚   â”œâ”€â”€ tsconfig.build.json         # Dependencies & scripts
â”‚   â”œâ”€â”€ tsconfig.json               # Dependencies & scripts
â”‚   â”œâ”€â”€ vercel.json                 # Dependencies & scripts
â”‚   â””â”€â”€
â”œâ”€â”€ client/                         # Frontend (Vue 3, Vuetify, TypeScript)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Vision.vue           # Main Vision Component (Controller)
â”‚   â”‚   â”‚   â”œâ”€â”€ CameraControls.vue   # Start/Stop Camera
â”‚   â”‚   â”‚   â”œâ”€â”€ DetectionResults.vue # Display Detection Output
â”‚   â”‚   â”‚   â”œâ”€â”€ ImageCapture.vue     # Capture Image (Training & Detection)
â”‚   â”‚   â”‚   â”œâ”€â”€ ModeSwitch.vue       # Toggle Detection/Training Mode
â”‚   â”œâ”€â”€ README.md                    # Frontend documentation
â”‚   â”œâ”€â”€ .env                         # Environment variables
â”‚   â”œâ”€â”€ .env.example                 # Environment variables
â”‚   â”œâ”€â”€ package.json                 # Dependencies & scripts
â”‚   â”œâ”€â”€ main.ts                      # Vue app entry point
â”‚   â”œâ”€â”€ router/index.ts              # Vue Router configuration
â”‚   â”œâ”€â”€ App.vue                      # Root Vue Component
â”‚   â”œâ”€â”€ styles/                      # SCSS / CSS styles
â”‚   â”œâ”€â”€ utils/LoggerService.ts       # Logging utility
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ index.html                   # Main HTML file
â”œâ”€â”€ package.json                     # Dependencies & scripts
â””â”€â”€ README.md                        # Root documentation (this file)
```

---

## ğŸ›  Setup & Installation

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your-repo/vision-ai.git
cd vision-ai
```

### 2ï¸âƒ£ Install Dependencies (**Using `pnpm`**)
This project uses **`pnpm`** as the package manager instead of `npm`. If you donâ€™t have `pnpm` installed, run:

```bash
npm install -g pnpm
```

Then install dependencies:

```bash
pnpm install
```

---

### 3ï¸âƒ£ Configure Environment Variables
Create a `.env` file in both **server** and **client** directories.

#### **Server `.env`**
```
PINECONE_API_KEY=your-pinecone-api-key
PINECONE_INDEX_NAME=image-recognition
PINECONE_DIMENSIONS=768
USE_CUSTOM_MODEL=false   # Set to 'true' to use the custom model in /models/mobilenet/mobilenet_tfjs/
```

#### **Client `.env`**
```
VITE_API_HOST=http://localhost:3000
```

---

## ğŸš€ Running the Application

### Start the **Backend Server**
```bash
cd server
pnpm dev
```

### Start the **Frontend (Vue 3)**
```bash
cd client
pnpm dev
```

By default, the frontend runs on **[http://localhost:5173](http://localhost:5173)**  
The backend runs on **[http://localhost:3000](http://localhost:8080)**

---

## ğŸ¯ Usage With ngrok
### **Step 1: Install**
```bash
brew install ngrok
```

### **Step 2: Login or Create an Account** 
- Sign up for a free ngrok account `https://dashboard.ngrok.com/signup`
- Login to your account `https://dashboard.ngrok.com/login`

### **Step 3: Get your Auth Token**
- In the ngrok Dashboard:
  - Getting Started
    - Your Authtoken

### **Step 3: Edit ngrok.yml file**
- `cd` into `~/Library/Application Support/ngrok`
- run `nano ngrok.yml`, (add your ngrok auth token) paste the following and save the file:
```bash
version: "3"
agent:
    authtoken: your-ngrok-auth-token
tunnels:
  frontend:
    addr: 5173
    proto: http
  backend:
    addr: 3000
    proto: http
```

### **Step 4: Start ngrok**
- `cd` into `vision-ai/server` and run the following command:
- run `ngrok start --all`
- Copy the URL for the backend tunnel
- Update the `VITE_API_HOST` variable in the client `.env` file

### **Step 5: Start the server and client**
#### Start the **Backend Server**
```bash
cd server
pnpm dev
```

#### Start the **Frontend (Vue 3)**
```bash
cd client
pnpm dev
```

### **Step 6: View in Mobile Device**
- copy the ngrok URL for the frontend tunnel
- open the URL in your mobile device browser

---

## ğŸ“– Documentation
For detailed information, check out the **individual README files**:

- ğŸ“œ **Backend Docs** â†’ [server/README.md](server/README.md)
- ğŸ“œ **Frontend Docs** â†’ [client/README.md](client/README.md)

---

## ğŸ“¬ Conclusion
With this guide, you should be able to:
- Start both the **server** and **client** applications.
- Capture images, train the AI, and detect objects.
- Debug issues using built-in logging.
- Use a pre-trained or custom MobileNet model.

ğŸš€ **Happy Coding!** ğŸ‰
